# This configuration is used to benchmark HPC systems
# It runs the benchmark model for a single file, over multiple epochs
training:
    trainer:
        type: keras
        # type: trainer
        # steps: 1
    optimizer:
        type: adam
        learning_rate:
            type: piecewise
            boundaries: [640] # Number of samples (not epochs)
            values: [1.0e-3, 1.0e-3]
    num_epochs: 10
    validation_frequency: 1 epoch # file
    # validation_frequency: 2 file
loader:
    type: file
    # filenames: [ "data/air_temperature/5TB/2020*1T*Z.nc"]
    filenames: [ "data/air_temperature/5TB/2020030*T*Z.nc", "data/air_temperature/5TB/2020031[012]T*Z.nc"]
    normalization: "data/air_temperature/normalization.yml"
    # limit_leadtimes: [0, 24, 48]
    # patch_size: 256
    predict_diff: True
    with_leadtime: False
    batch_size: 63
    prefetch: 1
    num_parallel_calls: 12
    debug: True
    extra_features:
        - type: leadtime
        - type: x
        - type: y
loader_validation1:
    type: file
    # filenames: [ "data/air_temperature/5TB/2021030[12]T*Z.nc"]
    filenames: ["data/air_temperature/5TB/20210301T*Z.nc",
                "data/air_temperature/5TB/20210315T*Z.nc",
                "data/air_temperature/5TB/20210402T*Z.nc",
                "data/air_temperature/5TB/20210416T*Z.nc",
                "data/air_temperature/5TB/20210501T*Z.nc",
                "data/air_temperature/5TB/20210515T*Z.nc",
                "data/air_temperature/5TB/20210602T*Z.nc",
                "data/air_temperature/5TB/20210616T*Z.nc",
                "data/air_temperature/5TB/20210701T*Z.nc",
                "data/air_temperature/5TB/20210715T*Z.nc",
                "data/air_temperature/5TB/20210802T*Z.nc",
                "data/air_temperature/5TB/20210816T*Z.nc",
                "data/air_temperature/5TB/20210901T*Z.nc",
                "data/air_temperature/5TB/20210915T*Z.nc",
                "data/air_temperature/5TB/20211002T*Z.nc",
                "data/air_temperature/5TB/20211016T*Z.nc",
                "data/air_temperature/5TB/20211101T*Z.nc",
                "data/air_temperature/5TB/20211115T*Z.nc",
                "data/air_temperature/5TB/20211202T*Z.nc",
                "data/air_temperature/5TB/20211216T*Z.nc",
                "data/air_temperature/5TB/20210101T*Z.nc",
                "data/air_temperature/5TB/20210115T*Z.nc",
                "data/air_temperature/5TB/20210202T*Z.nc",
                "data/air_temperature/5TB/20210216T*Z.nc"
    ]
    normalization: "data/air_temperature/normalization.yml"
    # limit_leadtimes: [0, 24, 48]
    patch_size: 256
    predict_diff: True
    with_leadtime: False
    batch_size: 100
    prefetch: 1
    num_parallel_calls: 12
    debug: False
    cache: True
    x_range: 300:1068
    y_range: 550:1062
    extra_features:
        - type: leadtime
        - type: x
        - type: y
models:
    - type: BasicBenchmark
      name: cnn
      leadtime_dependent: False
      neighbourhood_size: 3
      filter_sizes: [12, 5, 5]
    - type: Unet
      name: unet
      levels: 6
      with_leadtime: False
    - type: LocallyConnected
      name: local
output:
    quantiles: [0.5, 0.1, 0.9]
loss:
    type: quantile_score
evaluators:
    - type: aggregator
tensorflow:
    num_threads: 48
