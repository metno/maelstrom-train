# This configuration is used to benchmark HPC systems
# It runs the benchmark model for a single file, over multiple epochs
training:
    trainer:
        type: keras
    optimizer:
        type: adam
        learning_rate:
            type: piecewise
            boundaries: [10] # Number of samples (not epochs)
            values: [1.0e-2, 1.0e-3]
    num_epochs: 10
    validation_frequency: 1 epoch # file
loader:
    type: file
    # filenames: [ "data/air_temperature/5TB/20200301T*Z.nc"]  # One file
    filenames: [ "data/air_temperature/5TB/2020*1T*Z.nc"]    # 36 files
    # filenames: [ "data/air_temperature/5TB/2020*T*Z.nc", "data/air_temperature/5TB/20220[12]*T*Z.nc"]
    normalization: data/air_temperature/normalization.yml
    predict_diff: True
    patch_size: 512
    batch_size: 63
    with_leadtime: False
    num_parallel_calls: 12
    debug: False
    extra_features:
        - type: leadtime
        - type: x
        - type: y
loader_validation:
    type: file
    # filenames: [ "data/air_temperature/5TB/2021030[12]T*Z.nc"]
    filenames: ["data/air_temperature/5TB/20210301T*Z.nc",
                "data/air_temperature/5TB/20210315T*Z.nc",
                "data/air_temperature/5TB/20210402T*Z.nc",
                "data/air_temperature/5TB/20210416T*Z.nc",
                "data/air_temperature/5TB/20210501T*Z.nc",
                "data/air_temperature/5TB/20210515T*Z.nc",
                "data/air_temperature/5TB/20210602T*Z.nc",
                "data/air_temperature/5TB/20210616T*Z.nc",
                "data/air_temperature/5TB/20210701T*Z.nc",
                "data/air_temperature/5TB/20210715T*Z.nc",
                "data/air_temperature/5TB/20210802T*Z.nc",
                "data/air_temperature/5TB/20210816T*Z.nc",
                "data/air_temperature/5TB/20210901T*Z.nc",
                "data/air_temperature/5TB/20210915T*Z.nc",
                "data/air_temperature/5TB/20211002T*Z.nc",
                "data/air_temperature/5TB/20211016T*Z.nc",
                "data/air_temperature/5TB/20211101T*Z.nc",
                "data/air_temperature/5TB/20211115T*Z.nc",
                "data/air_temperature/5TB/20211202T*Z.nc",
                "data/air_temperature/5TB/20211216T*Z.nc",
                "data/air_temperature/5TB/20220101T*Z.nc",
                "data/air_temperature/5TB/20220115T*Z.nc",
                "data/air_temperature/5TB/20220202T*Z.nc",
                "data/air_temperature/5TB/20220216T*Z.nc"
    ]
    normalization: data/air_temperature/normalization.yml
    patch_size: 256
    batch_size: 1
    predict_diff: True
    with_leadtime: False
    num_parallel_calls: 12
    probabilistic_target: True
    debug: False
    cache: True
    # x_range: [300,1068]
    # y_range: [550,1062]
    x_range: [215, 1751]
    y_range: [50, 2097]
    extra_features:
        - type: leadtime
        - type: x
        - type: y
models:
    - type: BasicBenchmark
      name: cnn
      leadtime_dependent: False
      neighbourhood_size: 3
      filter_sizes: [12, 5, 5]
    - type: Unet
      name: unet
      levels: 6
    - type: dense
      layers: 3
      units: 12
      activation: "relu"
output:
    quantiles: [0.1, 0.5, 0.9]
loss:
    type: quantile_score_prob
    trim: 10
evaluators:
    - type: aggregator
tensorflow:
    num_threads: 48
